{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 for Sentiment Analysis on IMDb movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](##Introduction)\n",
    "2. [Data exploration](##Data-Exploration)\n",
    "3. [Zero Shot Classification](##Zero-shot-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The [IMDb](https://ai.stanford.edu/~amaas/data/sentiment/) is a binary sentiment classification dataset consisting of 100k movie reviews(50k positive and 50k negative). The dataset is split into train and test containing 50k reviews each.\n",
    "\n",
    "In this notebook, my goals are:\n",
    "1. Understand and implement [GPT-2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf). Run GPT-2 on the IMDb classification task.\n",
    "2. Fine-tune GPT-2 for sentiment classification in under ~30 minutes on a 8GB Nvidia 1080 GTX (Faster if you have a better, newer GPU).\n",
    "3. Understand how [LoRA](https://arxiv.org/abs/2106.09685) is implemented and use it to fine-tune GPT-2 for sentiment classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Exploration\n",
    "Get a summary of the dataset. i.e\n",
    "1. No of samples\n",
    "2. No of positive / negative samples.\n",
    "3. Length of the movie reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "import pandas\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from gpt_config import GPTConfig\n",
    "from reviewsDataset import reviewsDataset\n",
    "from eval import Eval\n",
    "from eval_config import EvalConfig\n",
    "from train import Trainer\n",
    "from train_config import TrainConfig\n",
    "from gpt_utils import start_recording, stop_recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset exploration\n",
    "\n",
    "imdb_train = reviewsDataset(\"train\",max_length=10000)\n",
    "imdb_test = reviewsDataset(\"test\",max_length=10000)\n",
    "\n",
    "\n",
    "def format_data(dataset: Dataset) -> pandas.DataFrame:\n",
    "\n",
    "    data = []\n",
    "    for batch in dataset:\n",
    "        data.append({\"input_ids\":len(batch[\"input_ids\"]),\n",
    "                    \"label\": batch[\"label\"],\n",
    "                    \"filename\": batch[\"fpath\"]})\n",
    "    \n",
    "    return pandas.DataFrame(data)\n",
    "\n",
    "train_data = format_data(imdb_train)\n",
    "test_data = format_data(imdb_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Summary statistics of the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(data: pandas.DataFrame) -> None:\n",
    "    print(f\"Number of reviews: {len(data)}\")\n",
    "    print(f\"Positive Reviews: {data[data['label'] == 1]['label'].count()}\")\n",
    "    print(f\"Negative Reviews: {data[data['label'] == 0]['label'].count()}\")\n",
    "    print(f\"Max Review Length: {data['input_ids'].max()}\\nMin Review Length: {data['input_ids'].min()}\")\n",
    "    print(f\"Median Review Length: {data['input_ids'].median()}\\nMean Review Length: {data['input_ids'].mean()}\")\n",
    "\n",
    "print(\"Train\\n--------------\")\n",
    "summary(train_data)\n",
    "print(\"Test\\n---------------\")\n",
    "summary(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Length of reviews (measured by the number of tokens)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_hist(title: str,df: pandas.DataFrame) -> None:\n",
    "    plt.figure()\n",
    "    plt.hist(df[\"input_ids\"],bins=100)\n",
    "    plt.xlabel(\"No of tokens\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"{title}\")\n",
    "\n",
    "plot_hist(title='Train Data', df=train_data) \n",
    "plot_hist(title=\"Test Data\", df=test_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(title=\"Positive Reviews Test\",df=test_data[test_data['label']==1])\n",
    "plot_hist(title=\"Negative Reviews Test\",df=test_data[test_data['label']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the test.py in `sentiment_classification` and write the results to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_by_bin(results, bins,threshold=0.5):\n",
    "    TP = len(results[(results[\"label\"] >= threshold) & (results[\"prediction\"] >= threshold)])\n",
    "    FP = len(results[(results[\"label\"] < threshold) & (results[\"prediction\"] >= threshold)])\n",
    "    TN = len(results[(results[\"label\"] < threshold) & (results[\"prediction\"] < threshold)])\n",
    "    FN = len(results[(results[\"label\"] > threshold) & (results[\"prediction\"] < threshold)])\n",
    "    \n",
    "    print(\"Metrics\")\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    print(f\"Precision: {precision}\\nRecall: {recall}\\nAccuracy: {accuracy}\")\n",
    "    results[\"bin\"] = pandas.cut(results['length'],bins)\n",
    "    metrics_by_bin = results.groupby('bin').apply(lambda x: pandas.Series({\"TP\": ((x[\"label\"] >= threshold) & (x[\"prediction\"] >= threshold)).sum(),\n",
    "                                                                            \"FP\":((x[\"label\"] < threshold) & (x[\"prediction\"] >= threshold)).sum(),\n",
    "                                                                            \"FN\": ((x[\"label\"] >= threshold) & (x[\"prediction\"] < threshold)).sum(),\n",
    "                                                                            \"TN\": ((x[\"label\"] < threshold) & (x[\"prediction\"] < threshold)).sum()}))\n",
    "\n",
    "    metrics_by_bin[\"accuracy\"] = (metrics_by_bin[\"TP\"] + metrics_by_bin[\"TN\"])/(metrics_by_bin[\"TP\"] + metrics_by_bin[\"TN\"]+ metrics_by_bin[\"FP\"]+ metrics_by_bin[\"FN\"])\n",
    "    metrics_by_bin[\"precision\"] = metrics_by_bin[\"TP\"]/(metrics_by_bin[\"TP\"] + metrics_by_bin[\"FP\"])\n",
    "    metrics_by_bin[\"recall\"] = metrics_by_bin[\"TP\"]/(metrics_by_bin[\"TP\"] + metrics_by_bin[\"FN\"])\n",
    "    print(\"Metrics by bin\")\n",
    "    print(metrics_by_bin.to_markdown())\n",
    "    return {\"precision\":precision,\"recall\":recall,\"accuracy\":accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot\n",
    "\n",
    "### Predict the next word given the following prompt\n",
    " \n",
    "Review: {review} Sentiment:\n",
    "\n",
    "I calculate the probabilities of the word \" Positive\" and \" Negative\" and classify the review based on which probability is greater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run evaluation for the zero shot approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_recording(\"gpu_memory_log.txt\")\n",
    "model_config = GPTConfig(block_size=256,use_lora=False)\n",
    "eval_config = EvalConfig(results_path=\"zero_shot_256.txt\",subset=True,batch_size=128)\n",
    "test_set = reviewsDataset(split=\"test\",max_length=model_config.block_size)\n",
    "evaluator = Eval(test_set=test_set,eval_config=eval_config,model_config=model_config)\n",
    "evaluator.evaluate()\n",
    "stop_recording()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_file = pandas.read_csv(\"zero_shot_256.txt\")\n",
    "bins = range(0,1500,256)\n",
    "get_metrics_by_bin(res_file,bins,threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finetuning without LoRA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained weights for gpt2\n",
      "Number of parameters: 123.65M\n",
      "num decayed parameter tensors: 9, with 14,156,544 parameters\n",
      "num non-decayed parameter tensors: 19, with 21,505 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/60000 [00:06<26:34:04,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      " Train Loss: 1.3199241161346436\n",
      "Validation Loss: 1.3183265924453735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 1998/60000 [01:26<38:59, 24.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2000\n",
      " Train Loss: 0.7388057112693787\n",
      "Validation Loss: 0.7314255237579346\n",
      "Saving checkpoint to run/10_layer_freeze/finetune_no_lora.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 4000/60000 [02:54<38:55, 23.98it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4000\n",
      " Train Loss: 0.2787182927131653\n",
      "Validation Loss: 0.2372196614742279\n",
      "Saving checkpoint to run/10_layer_freeze/finetune_no_lora.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 4893/60000 [03:39<41:06, 22.34it/s]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m train_set, val_set \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mrandom_split(rd,[\u001b[38;5;241m0.85\u001b[39m,\u001b[38;5;241m0.15\u001b[39m])\n\u001b[1;32m      6\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(train_set,val_set,train_config,model_config)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m stop_recording()\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/sentiment-classification/train.py:113\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     target \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_idxs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 113\u001b[0m logits, loss, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreview_lens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    118\u001b[0m     param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_lr()\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/gpt.py:167\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, review_lens, target)\u001b[0m\n\u001b[1;32m    165\u001b[0m     x, att_layer \u001b[38;5;241m=\u001b[39m block(x)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     x , _ \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     att_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    169\u001b[0m att_out\u001b[38;5;241m.\u001b[39mappend(att_layer)\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/gpt.py:82\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m     att_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x))\n\u001b[0;32m---> 82\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, att_out\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/gpt.py:61\u001b[0m, in \u001b[0;36mFeedForward.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_fc(x)\n\u001b[1;32m     60\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgelu(x)\n\u001b[0;32m---> 61\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_proj\u001b[49m(x)\n\u001b[1;32m     62\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_recording(\"without_lora.txt\")\n",
    "train_config = TrainConfig(out_dir=\"run/10_layer_freeze/\",init_from=\"gpt2\",checkpoint_name=\"finetune_no_lora.ckpt\")\n",
    "model_config = GPTConfig(use_lora=False,block_size=256,binary_classification_head=True)\n",
    "rd = reviewsDataset(split=\"train\",max_length=model_config.block_size)\n",
    "train_set, val_set = torch.utils.data.random_split(rd,[0.85,0.15])\n",
    "trainer = Trainer(train_set,val_set,train_config,model_config)\n",
    "trainer.train()\n",
    "stop_recording()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run eval using the fine-tuned model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = GPTConfig(block_size=256,use_lora=False,load_from_checkpoint=True,binary_classification_head=True,checkpoint_path=\"run/10_layer_freeze/finetune_no_lora.ckpt\")\n",
    "eval_config = EvalConfig(results_path=\"finetuned_no_lora.txt\",subset=False)\n",
    "test_set = reviewsDataset(split=\"test\",cache_dir=\"/home/varun/Downloads/aclImdb/\",max_length=256)\n",
    "evaluator = Eval(test_set=test_set,eval_config=eval_config,model_config=model_config)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the performance of the fine-tuned model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_file = pandas.read_csv(\"finetuned_no_lora.txt\")\n",
    "bins = range(0,1500,256)\n",
    "get_metrics_by_bin(res_file,bins,threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run training using LoRA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained weights for gpt2\n",
      "Number of parameters: 123.65M\n",
      "num decayed parameter tensors: 5, with 49,920 parameters\n",
      "num non-decayed parameter tensors: 0, with 0 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/40000 [00:06<13:34:58,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      " Train Loss: 1.3143283128738403\n",
      "Validation Loss: 1.202756404876709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 1026/40000 [00:48<30:39, 21.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m train_set, val_set \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mrandom_split(rd,[\u001b[38;5;241m0.85\u001b[39m,\u001b[38;5;241m0.15\u001b[39m])\n\u001b[1;32m     12\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(train_set,val_set,train_config,model_config)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/sentiment-classification/train.py:113\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     target \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_idxs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 113\u001b[0m logits, loss, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreview_lens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    118\u001b[0m     param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_lr()\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/gpt.py:173\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, review_lens, target)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# To finetune, want to calculate the loss only on the last token\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbinary_classification_head:\n\u001b[0;32m--> 173\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification_head(torch\u001b[38;5;241m.\u001b[39mstack([x[i,review_lens[i]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(review_lens))],dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m         loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(logits\u001b[38;5;241m.\u001b[39msqueeze(),target\u001b[38;5;241m=\u001b[39mtarget)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_recording(\"with_lora.txt\")\n",
    "train_config = TrainConfig(out_dir=\"run/10_layer_freeze_lora\",\n",
    "                            checkpoint_name=\"finetune_lora.ckpt\",\n",
    "                            init_from=\"gpt2\")\n",
    "model_config = GPTConfig(block_size=256,\n",
    "                        use_lora=True,\n",
    "                        r=8,\n",
    "                        lora_layers=(10,11),\n",
    "                        binary_classification_head=True)\n",
    "rd = reviewsDataset(split=\"train\",max_length=model_config.block_size,cache_dir=\"/home/varun/Downloads/aclImdb/\")\n",
    "train_set, val_set = torch.utils.data.random_split(rd,[0.85,0.15])\n",
    "trainer = Trainer(train_set,val_set,train_config,model_config)\n",
    "trainer.train()\n",
    "stop_recording()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate using the LoRA finetuned model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_config = GPTConfig(load_from_checkpoint=True,checkpoint_path=\"run/10_layer_freeze_lora/finetune_lora.ckpt\")\n",
    "eval_config = EvalConfig(results_path=\"run/10_layer_freeze_lora/finetuned_lora.txt\",batch_size=8,subset=False)\n",
    "test_set = reviewsDataset(split=\"test\",cache_dir=\"/home/varun/Downloads/aclImdb/\",max_length=model_config.block_size)\n",
    "evaluator = Eval(test_set=test_set,eval_config=eval_config,model_config=model_config)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_file = pandas.read_csv(\"run/10_layer_freeze_lora/finetuned_lora.txt\")\n",
    "bins = range(0,1500,256)\n",
    "results = get_metrics_by_bin(res_file,bins,threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_246488/1019155924.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv(log_file, names=[\"timestamp\", \"memory\"], sep=\", \")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "log_file = \"with_lora.txt\"\n",
    "data = pd.read_csv(log_file, names=[\"timestamp\", \"memory\"], sep=\", \")\n",
    "data[\"memory\"] = data[\"memory\"].str.replace(\" MiB\", \"\").astype(int)\n",
    "\n",
    "# Plot memory usage\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(pd.to_datetime(data[\"timestamp\"]), data[\"memory\"], label=\"GPU Memory Usage\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Memory Usage (MB)\")\n",
    "plt.title(\"GPU Memory Usage Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
