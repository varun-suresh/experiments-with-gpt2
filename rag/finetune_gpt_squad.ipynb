{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune GPT-2 using SQuAD \n",
    "\n",
    "SQuAD (Stanford Question Answes Dataset) contains reading comprehension tasks. I want to finetune GPT-2 on this dataset and use the finetuned version in my RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/varun/projects/experiments-with-gpt2/\")\n",
    "from squadDataset import squadDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from gpt_utils import dynamic_padding_squad\n",
    "\n",
    "train_set = squadDataset(\"train\")\n",
    "val_set = squadDataset(\"validation\")\n",
    "for item in train_set:\n",
    "    print(item[\"answer\"])\n",
    "    # break\n",
    "# dl = DataLoader(train_set,batch_size=1,collate_fn=dynamic_padding_squad)\n",
    "# for batch in dl:\n",
    "#     if len(batch[\"answer_ids\"][0]) == 0:\n",
    "#         print(batch.keys())\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained weights for gpt2\n",
      "Number of parameters: 123.65M\n",
      "num decayed parameter tensors: 16, with 28,311,552 parameters\n",
      "num non-decayed parameter tensors: 34, with 41,472 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/160000 [00:03<31:33:48,  1.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      " Train Loss: 4.994784832000732\n",
      "Validation Loss: 5.100532054901123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1996/160000 [00:53<1:05:40, 40.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2000\n",
      " Train Loss: 1.9299663305282593\n",
      "Validation Loss: 1.7530447244644165\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3998/160000 [01:49<1:04:16, 40.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4000\n",
      " Train Loss: 1.8768703937530518\n",
      "Validation Loss: 1.7470016479492188\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 5996/160000 [02:46<1:03:33, 40.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6000\n",
      " Train Loss: 1.7219979763031006\n",
      "Validation Loss: 1.6152600049972534\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8000/160000 [03:41<1:07:25, 37.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8000\n",
      " Train Loss: 1.3234409093856812\n",
      "Validation Loss: 1.4471139907836914\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9997/160000 [04:38<1:00:25, 41.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10000\n",
      " Train Loss: 1.5161771774291992\n",
      "Validation Loss: 1.9461159706115723\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11998/160000 [05:35<1:01:27, 40.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12000\n",
      " Train Loss: 1.5586233139038086\n",
      "Validation Loss: 1.4795598983764648\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 13999/160000 [06:30<59:32, 40.87it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14000\n",
      " Train Loss: 1.4006863832473755\n",
      "Validation Loss: 1.4473577737808228\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 15996/160000 [07:27<58:21, 41.13it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 16000\n",
      " Train Loss: 1.442601203918457\n",
      "Validation Loss: 1.371037483215332\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 18000/160000 [08:23<56:54, 41.59it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 18000\n",
      " Train Loss: 1.2876930236816406\n",
      "Validation Loss: 1.3080843687057495\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 19999/160000 [09:19<55:51, 41.77it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20000\n",
      " Train Loss: 1.2848738431930542\n",
      "Validation Loss: 1.6305761337280273\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 21996/160000 [10:16<54:17, 42.36it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 22000\n",
      " Train Loss: 1.5968427658081055\n",
      "Validation Loss: 1.8835529088974\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 23998/160000 [11:13<55:55, 40.53it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 24000\n",
      " Train Loss: 1.0988125801086426\n",
      "Validation Loss: 1.6705877780914307\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 26000/160000 [12:09<59:39, 37.44it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 26000\n",
      " Train Loss: 0.8851484060287476\n",
      "Validation Loss: 1.5610607862472534\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 27996/160000 [13:06<52:39, 41.78it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 28000\n",
      " Train Loss: 1.4041810035705566\n",
      "Validation Loss: 1.410149097442627\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 29996/160000 [14:03<56:17, 38.49it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 30000\n",
      " Train Loss: 1.1717323064804077\n",
      "Validation Loss: 1.5055804252624512\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 31996/160000 [14:59<52:58, 40.27it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 32000\n",
      " Train Loss: 1.033320665359497\n",
      "Validation Loss: 1.4146637916564941\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 33998/160000 [15:57<53:07, 39.53it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 34000\n",
      " Train Loss: 1.0374239683151245\n",
      "Validation Loss: 1.3864998817443848\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 35997/160000 [16:54<51:57, 39.78it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 36000\n",
      " Train Loss: 1.101700782775879\n",
      "Validation Loss: 1.1956504583358765\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 38000/160000 [17:50<54:54, 37.03it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 38000\n",
      " Train Loss: 0.949032723903656\n",
      "Validation Loss: 1.6524070501327515\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 39999/160000 [18:47<46:46, 42.76it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 40000\n",
      " Train Loss: 0.9406406879425049\n",
      "Validation Loss: 1.3440618515014648\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 41998/160000 [19:45<52:06, 37.75it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 42000\n",
      " Train Loss: 0.9173780083656311\n",
      "Validation Loss: 1.2030224800109863\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 43999/160000 [20:41<46:48, 41.30it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 44000\n",
      " Train Loss: 0.8679404258728027\n",
      "Validation Loss: 1.4362791776657104\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 45996/160000 [21:38<50:42, 37.46it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 46000\n",
      " Train Loss: 0.738576352596283\n",
      "Validation Loss: 1.1237584352493286\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 47997/160000 [22:35<42:52, 43.54it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 48000\n",
      " Train Loss: 0.6745953559875488\n",
      "Validation Loss: 1.2398717403411865\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 49999/160000 [23:32<44:20, 41.35it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50000\n",
      " Train Loss: 0.8527186512947083\n",
      "Validation Loss: 1.2028594017028809\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 52000/160000 [24:29<43:09, 41.70it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 52000\n",
      " Train Loss: 0.7531907558441162\n",
      "Validation Loss: 1.3585925102233887\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 53995/160000 [25:27<49:38, 35.58it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 54000\n",
      " Train Loss: 0.935933530330658\n",
      "Validation Loss: 1.1668667793273926\n",
      "Saving checkpoint to out/squad_ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 54170/160000 [25:37<50:03, 35.23it/s]   \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Sequence length 25731 is larger than the block size 1024",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m model_config \u001b[38;5;241m=\u001b[39m GPTConfig(block_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,use_lora\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(train_set, val_set,train_config,model_config)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/sentiment_classification/train.py:118\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# logits, loss, _ = self.model(batch[\"input_ids\"].to(self.train_config.device),\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m#                         batch[\"review_lens\"].to(self.train_config.device),\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m#                         target=target.to(self.train_config.device))\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m logits, loss, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion_lengths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer_lengths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    123\u001b[0m     param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_lr()\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/experiments-with-gpt2/gpt.py:156\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, question_lengths, answer_lengths, target)\u001b[0m\n\u001b[1;32m    153\u001b[0m device \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    154\u001b[0m b, t \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 156\u001b[0m     t \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mblock_size\n\u001b[1;32m    157\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is larger than the block size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mblock_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, t, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    159\u001b[0m tok_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mwte(idx)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Sequence length 25731 is larger than the block size 1024"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/varun/projects/experiments-with-gpt2/\")\n",
    "from squadDataset import squadDataset\n",
    "from sentiment_classification.train import Trainer\n",
    "from sentiment_classification.train_config import TrainConfig\n",
    "from gpt_config import GPTConfig\n",
    "\n",
    "train_set = squadDataset(\"train\")\n",
    "val_set = squadDataset(\"validation\")\n",
    "train_config = TrainConfig(checkpoint_name=\"squad_ckpt.pt\",micro_batch_size=1,init_from=\"resume\")\n",
    "model_config = GPTConfig(block_size=1024,use_lora=False)\n",
    "trainer = Trainer(train_set, val_set,train_config,model_config)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokenizer.decode([193])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
