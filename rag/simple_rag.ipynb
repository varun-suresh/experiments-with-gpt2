{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG\n",
    "\n",
    "Build a simple Retrieval-Augmented Generation pipeline to demonstrate its working.\n",
    "\n",
    "Steps:\n",
    "1. Document Store: Use in-memory key-value store.\n",
    "2. Retrieval: Use embeddings from GPT-2\n",
    "3. Generation: Use GPT-2 for generating a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 7592, 1010, 2088,  102, 2117, 6251,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[-4.1294e-01, -7.1324e-02,  1.3854e-01, -1.6372e-01,  1.9077e-02,\n",
      "          4.8927e-02,  4.5613e-01,  3.8596e-01, -5.4269e-01, -5.7494e-01,\n",
      "         -1.9105e-01,  1.0720e-01,  2.0602e-01,  5.7859e-01,  3.9898e-02,\n",
      "         -3.0058e-02,  1.6359e-02,  4.8764e-01,  1.8919e-01, -4.8697e-01,\n",
      "          3.2901e-01,  4.0074e-02, -1.2393e-03, -5.2827e-02,  6.9944e-02,\n",
      "         -1.0699e-02, -4.7424e-01,  1.7889e-01, -3.4116e-01, -1.2349e-01,\n",
      "         -1.7821e-01, -9.2627e-02,  1.0770e-01,  2.7475e-01,  2.9903e-01,\n",
      "         -4.1094e-01, -2.5761e-01,  5.3917e-02, -1.6200e-01,  2.0917e-01,\n",
      "          1.5174e-01, -1.5715e-01,  6.5028e-02, -1.6512e-01,  4.2797e-02,\n",
      "         -2.3322e-03, -2.5327e+00, -2.0062e-01, -2.0991e-01,  3.8807e-02,\n",
      "         -5.7647e-02, -2.8008e-01,  1.5989e-01,  6.6906e-02, -9.6201e-02,\n",
      "          6.3356e-01,  2.6311e-01,  4.4277e-01,  1.9647e-01,  1.1194e-01,\n",
      "          3.5518e-01, -7.0677e-01, -2.3053e-01, -1.0684e-01,  1.1028e-01,\n",
      "          4.8784e-02, -2.3908e-02,  6.7764e-01, -3.1975e-01,  5.0115e-01,\n",
      "         -8.9132e-02,  5.8223e-02,  2.1920e-01, -4.7669e-02,  8.7472e-02,\n",
      "         -3.5685e-01, -1.6307e-01,  2.6710e-01, -5.0512e-01, -4.2085e-01,\n",
      "         -1.3737e-01,  1.9432e-02,  1.5273e-01, -2.2730e-03,  3.0966e-01,\n",
      "          1.1073e-01, -3.9278e-01, -4.7700e-01, -3.8512e-02,  4.4314e-01,\n",
      "          1.3608e-01, -1.8602e-01, -2.3903e-01,  4.8164e-01,  3.6202e-01,\n",
      "         -3.0778e-01,  5.7669e-02,  1.7404e-01, -2.9840e-01, -3.1715e-02,\n",
      "         -2.7396e-01, -2.4904e-02,  5.6604e-01, -3.0927e-01,  5.0460e-01,\n",
      "          6.4221e-02,  3.2736e-02, -2.8365e-01,  2.5336e-01, -2.1012e+00,\n",
      "          4.8113e-01,  2.1969e-01, -6.6404e-02, -3.1569e-01, -1.5259e-01,\n",
      "          5.2052e-01,  4.4180e-01, -3.0109e-01,  1.9362e-01,  3.2677e-01,\n",
      "         -1.9858e-01,  6.3807e-02, -2.1440e-01, -2.4924e-03,  3.4314e-01,\n",
      "          4.6359e-01, -1.9003e-01, -2.9228e-01,  6.2726e-01, -1.2246e-01,\n",
      "          2.9774e-02,  2.2952e-01, -6.6754e-03, -1.3199e-01, -3.4498e-02,\n",
      "          3.2103e-01,  3.5456e-01, -1.0666e-02,  1.0336e-01, -1.7343e-01,\n",
      "         -5.7524e-01, -2.5120e-01, -2.2845e+00, -5.9614e-02,  9.2245e-01,\n",
      "          3.6568e-01, -5.9079e-01,  4.9278e-01,  3.8290e-01,  1.5406e-01,\n",
      "         -5.9487e-01,  1.7622e-01, -8.9986e-02, -1.3944e-02, -1.6677e-01,\n",
      "         -4.7567e-01,  8.0040e-01, -3.6083e-02,  2.6110e-02,  6.7889e-01,\n",
      "          3.7294e-01, -7.3540e-02, -1.3617e-02,  2.2619e-01, -4.6371e-01,\n",
      "          1.3951e-01,  3.0712e-01,  1.7269e-01,  4.3212e-01, -1.5703e-01,\n",
      "         -2.6880e-01,  7.1840e-02,  4.9210e-01,  8.0698e-02, -2.5757e-02,\n",
      "         -2.8323e-01,  5.2138e-01,  2.0060e-01,  1.1236e-01, -4.1051e-01,\n",
      "         -2.4158e-01,  3.1034e-01, -3.5593e-01, -1.8131e-01,  4.0219e-01,\n",
      "         -8.9925e-03,  1.9028e-01,  4.7876e-02,  9.7015e-03,  1.8367e-01,\n",
      "         -4.0487e-01, -6.0550e-01, -4.0722e-02, -1.2294e-02,  4.1797e-01,\n",
      "          1.2084e-01,  1.2251e-01, -4.4609e-01, -2.1111e-01,  4.1251e-01,\n",
      "          5.8069e-01,  2.9395e-01,  2.7993e-01,  3.4357e-01, -6.7785e-02,\n",
      "          3.1136e+00, -1.9871e-01, -9.5667e-02,  2.4215e-01,  9.0405e-01,\n",
      "         -5.5182e-01,  5.6391e-01,  8.1704e-02,  7.7378e-02,  4.3814e-02,\n",
      "          1.3340e-01,  3.8832e-01, -1.0467e-01, -3.0994e-02,  5.2875e-01,\n",
      "          1.1168e-01, -1.5845e-01,  1.3578e-02,  2.5410e-01, -2.6380e-01,\n",
      "          6.3978e-02,  1.0984e-01,  5.6291e-02, -5.6910e-02, -7.3439e-01,\n",
      "          5.3542e-02, -1.0243e-01, -3.4372e-01,  4.3170e-01,  7.8500e-02,\n",
      "          3.0087e-01, -2.3545e-01, -4.0462e-01, -2.6838e-01,  2.2734e-01,\n",
      "         -1.6481e-01,  5.7065e-02,  5.2815e-01,  2.0602e-01, -3.2908e-01,\n",
      "         -1.7216e-01,  5.6146e-01, -1.2923e-01,  5.5144e-01,  1.8698e-01,\n",
      "          2.5933e-01, -3.8166e-01,  3.9295e-02, -3.2842e-01,  3.1086e-01,\n",
      "          5.8610e-01,  1.0778e-01,  1.7932e-03, -3.1039e-01, -2.0937e-01,\n",
      "         -2.2561e-01, -1.4728e-01,  1.1854e-01, -1.5504e-01, -3.6392e-01,\n",
      "          4.0938e-01,  1.8659e-01, -4.2466e-01,  4.1437e-01, -3.1674e-02,\n",
      "         -2.1307e-01, -1.5641e-01, -1.7272e-01, -2.7859e+00,  1.5515e-01,\n",
      "          2.2939e-01,  7.1618e-01,  2.1127e-01, -1.6416e-01, -2.0950e-01,\n",
      "          2.7932e-01, -1.2867e-01, -3.0677e-01,  2.1901e-01,  5.4933e-02,\n",
      "         -7.5517e-01,  3.3355e-01, -5.8047e-01,  1.3421e-01, -1.8145e-01,\n",
      "         -3.1915e-01, -2.2607e-01,  2.3979e-02,  5.7460e-01,  4.7090e-01,\n",
      "         -2.7911e-01,  1.1316e-01,  2.7580e-01,  1.1290e-01, -2.0143e-01,\n",
      "         -1.1703e-01,  3.4448e-01, -2.2141e-01,  3.6636e-02, -2.6182e-01,\n",
      "          1.9868e-01,  2.4583e-02, -3.6911e-01, -4.5284e+00,  1.2080e-02,\n",
      "         -2.6854e-02, -5.8804e-01,  7.6006e-02,  8.0604e-02,  6.7668e-01,\n",
      "          3.4877e-01,  1.1552e-01, -2.3407e-01,  1.4889e-01, -1.0020e-01,\n",
      "          3.2690e-01,  2.0078e-01, -2.2431e-01, -1.1270e-01,  2.5130e-01,\n",
      "          4.2333e-01, -1.2851e-01,  3.3579e-01, -2.2824e-01,  1.5080e-01,\n",
      "          3.8324e-01, -4.0954e-01, -1.3127e-01,  3.5818e-01, -1.8556e-01,\n",
      "          4.0160e-02, -1.9638e-01, -2.6143e-01,  2.0199e-01, -3.9350e-02,\n",
      "          1.0254e-01, -1.8157e-01, -2.9443e-01,  9.8737e-02,  3.2671e-01,\n",
      "          4.8044e-01,  9.5386e-01,  2.3663e-01,  2.3522e-01,  2.5683e-02,\n",
      "         -2.3157e-01,  4.9064e-01,  1.7541e-01,  4.0187e-03, -3.9938e-01,\n",
      "         -2.0593e-01,  1.1784e-01,  1.2195e-01, -5.9568e-01, -1.1236e-01,\n",
      "          1.0474e+00, -7.0362e-02,  5.5329e-01,  2.9892e-01, -5.5856e-02,\n",
      "          2.0032e-01,  1.1782e-01, -3.4075e-01,  7.8029e-01, -3.4169e-01,\n",
      "          3.9755e-01, -9.6931e-02,  3.0216e-01, -3.5837e-01,  1.9095e-01,\n",
      "         -4.2394e-01, -3.1089e-02,  2.3986e-01, -3.3745e-01, -4.3703e-01,\n",
      "          1.1250e-01, -9.2024e-01,  7.2099e-02,  2.8230e-01, -1.5293e-01,\n",
      "          9.4778e-02,  5.4086e-02, -4.2192e-01, -2.0102e-01,  2.6018e-01,\n",
      "         -7.7944e-02,  7.1514e-01, -2.4536e-01,  1.1442e-01, -1.4377e-01,\n",
      "          2.2426e-02, -1.6609e-01,  1.0504e-01, -2.3746e-01,  2.3220e-01,\n",
      "         -5.0054e-02, -2.3759e-01, -4.2839e-02,  5.0942e-01,  4.9632e-01,\n",
      "         -6.9217e-01, -7.3064e-02, -1.5627e-01,  9.6893e-02, -3.5400e-01,\n",
      "          3.1768e-01, -1.4549e-01, -1.8889e-01, -6.4458e-02, -9.2326e-01,\n",
      "          4.6115e-01,  9.8905e-02,  1.4544e-02,  1.3324e-01, -1.2048e-01,\n",
      "          5.7879e-02,  3.2468e-01,  4.7837e-01, -1.6974e-01, -3.9215e-01,\n",
      "          2.7476e-01, -5.3150e-02,  4.2851e-02,  2.4012e-01, -1.6614e-01,\n",
      "         -2.7726e-01, -9.6222e-02, -1.4337e-01, -1.9937e-01,  6.6159e-02,\n",
      "          3.4869e-01, -1.7489e-01, -3.7308e-01,  3.3466e-02, -2.4514e-02,\n",
      "         -3.0325e-01, -6.6496e-01,  6.5163e-02, -1.5651e-01, -1.8879e-01,\n",
      "         -4.7796e-02,  5.1214e-01,  4.9140e-03,  8.8701e-02, -5.7680e-01,\n",
      "         -5.7152e-01,  5.1065e-01,  1.1528e-01,  4.6695e-01, -4.9403e-01,\n",
      "         -3.3951e-01, -3.2841e-01,  1.8524e-01,  2.2115e-01, -5.4899e-01,\n",
      "          4.7663e-01, -4.5720e-01,  1.0610e-02, -1.9663e-02, -1.1867e-01,\n",
      "          2.1062e-01, -6.4095e-02,  3.9190e-01,  1.7816e-01, -2.7888e-01,\n",
      "         -8.1797e-01,  1.4497e-01, -3.3496e-01, -1.7546e-01,  7.6844e-02,\n",
      "          1.3220e-01, -4.4033e-01,  3.5069e-01, -2.1282e-02, -1.7270e-01,\n",
      "         -1.2567e-01,  1.9630e-01,  4.7813e-03,  6.3067e-01,  1.4775e-02,\n",
      "         -1.7087e-01,  1.8194e-01,  1.6377e-01,  4.1595e-02,  1.4357e-01,\n",
      "          6.0635e-02,  5.0432e-01, -1.9198e-03, -1.9311e-01,  3.2852e-01,\n",
      "          9.9031e-02,  2.4385e-01,  1.0558e-01, -2.8178e-01, -1.4245e-01,\n",
      "          8.2565e-02, -3.8859e-01, -3.9336e-01, -5.5280e-01,  2.9299e-01,\n",
      "          3.5114e-01,  1.1630e-01,  2.6267e-01,  4.4810e-01,  9.2976e-02,\n",
      "         -4.3185e-02,  1.1543e-01,  3.1199e-01,  4.7020e-02,  5.7593e-01,\n",
      "          2.0803e-01,  1.0809e-01,  3.2726e-01,  5.2225e-01, -2.6265e-01,\n",
      "          3.4608e-01, -3.8570e-01, -4.6377e-02, -2.4126e-01,  6.2491e-02,\n",
      "         -7.1946e-02, -1.6466e-01,  1.2300e-02, -2.1882e-01, -5.9753e-01,\n",
      "         -3.7403e-02,  3.6474e-02, -2.8631e-01,  3.1718e-01, -3.7747e-01,\n",
      "         -6.1268e-01,  2.9693e-01, -1.8153e-01, -2.9376e-02,  2.3147e-01,\n",
      "          3.8122e-01,  3.8325e-02,  3.2946e-02, -7.4476e-01, -9.0420e-01,\n",
      "          2.2956e-02, -1.4386e-01,  4.4032e-01,  4.0313e-02, -1.8538e-01,\n",
      "          4.6899e-02, -8.7854e-01, -1.6941e-01,  4.3183e-01,  2.3397e-01,\n",
      "         -2.6174e-01,  2.8950e-01,  5.5765e-01,  1.8500e-01,  3.0773e-02,\n",
      "         -1.6526e-01, -1.9800e-01,  1.7438e-01, -2.1195e-01, -6.0584e-01,\n",
      "         -2.2454e-01, -1.0964e-01,  5.2045e-01, -4.1339e-01,  2.4557e-01,\n",
      "         -3.0634e-01,  3.6216e-01,  5.1061e-01,  4.2722e-01,  2.8642e-02,\n",
      "          2.7503e-01,  3.6522e-01,  3.5243e-01, -3.1112e-01,  1.7077e-01,\n",
      "         -3.5655e-02,  5.0293e-02, -8.8477e-02,  2.9825e-01, -2.6451e-01,\n",
      "          1.3784e-01,  3.4710e-01, -3.7046e-01,  1.5585e+00,  4.3446e-01,\n",
      "         -3.1416e-01, -2.9650e-02,  5.6984e-01, -2.6691e-01, -4.1907e-01,\n",
      "         -5.4794e-01, -5.2150e-01,  2.6670e-01,  1.5909e-02,  3.0951e-01,\n",
      "          1.0539e-01,  3.1402e-01,  3.8735e-01,  4.0856e-01, -1.6801e-01,\n",
      "         -2.1094e-01, -7.1858e-01,  1.1958e-01, -3.9318e-01,  5.2946e-01,\n",
      "          5.4311e-01, -6.6975e-01,  1.1007e-01,  1.7713e-01,  1.1231e-01,\n",
      "         -2.5975e-01,  5.2731e-03, -2.7255e-02,  4.6681e-02, -1.4466e-01,\n",
      "          2.3569e-01,  5.3796e-01, -4.8088e-02,  2.2526e-01,  1.0182e-01,\n",
      "         -2.6976e-01, -5.9104e-01, -4.4973e-02,  6.8319e-02, -2.8258e-01,\n",
      "          5.1225e-01, -1.0211e-01, -1.6597e-01,  5.0785e-01, -5.6330e-01,\n",
      "         -1.0880e-01,  1.0206e-02, -2.0971e-02, -1.1358e-01, -1.0641e-01,\n",
      "         -3.1076e-01, -1.3836e-01, -9.4130e-02, -3.7811e-01, -1.1343e-01,\n",
      "         -2.9077e-01, -1.5521e-01,  4.2677e-01,  2.2719e-01,  3.6334e-01,\n",
      "          1.7532e-01, -1.6565e-01, -6.4503e-03, -1.2518e-01, -3.5794e-01,\n",
      "          3.3299e-01,  5.6035e-01,  6.1277e-01,  2.1027e-02,  2.2379e-01,\n",
      "          5.7893e-01,  7.9258e-03,  1.1912e-01,  1.4508e-01,  3.1177e-01,\n",
      "         -3.0948e-01, -2.8844e-01, -2.4852e+00, -2.1165e-01, -1.1372e-01,\n",
      "          5.6963e-01, -2.9940e-02,  2.8200e-01, -1.5405e-03,  1.5730e-01,\n",
      "          1.3309e-02, -1.2863e-01,  8.4194e-02,  4.5196e-01, -4.5797e-02,\n",
      "         -1.4365e-01,  2.6838e-01, -2.3224e-01,  2.6901e-01, -4.5302e-01,\n",
      "         -1.8339e-01, -5.9455e-02,  5.3530e-03,  4.0576e-02, -1.1953e-01,\n",
      "          3.5320e-01, -2.6589e-01,  3.3820e-01,  1.4980e-01, -3.0785e-01,\n",
      "         -1.7805e-02, -2.8079e-02, -4.1683e-01, -1.2110e-01, -2.3094e-01,\n",
      "         -6.5247e-02,  8.9285e-02, -3.3153e-01,  4.8667e-02,  2.6351e-04,\n",
      "          1.2133e-01,  4.2978e-01,  2.9092e-01,  5.5234e-01, -8.7553e-02,\n",
      "          4.5797e-01, -2.7272e-01, -2.5633e-02,  2.3582e-01, -2.1134e-01,\n",
      "          4.8046e-01,  8.7265e-02,  2.5992e-01, -1.5366e-01,  1.2447e-01,\n",
      "         -2.5429e-01, -6.2879e-02,  1.8224e-01, -1.6348e-01,  3.8310e-02,\n",
      "          6.6618e-02, -2.3382e-01, -1.3826e-01, -1.6734e-01, -1.7907e-01,\n",
      "          2.6712e-01,  3.8526e-01, -3.5269e-01,  6.7392e-02, -2.7301e-01,\n",
      "          3.7728e-02, -7.9189e-03, -1.0020e-01, -3.0273e-01,  3.9817e-01,\n",
      "          6.1432e-02, -2.6281e-01,  2.7411e-01,  3.3689e-01,  7.1548e-02,\n",
      "         -2.6807e-01,  1.2502e-01, -3.5557e-01, -4.4725e-01,  1.5152e-01,\n",
      "         -6.4682e-02,  3.5891e-01, -6.3050e+00, -4.5239e-01,  1.1722e-01,\n",
      "         -1.7043e-01, -4.1566e-02, -7.1317e-01,  1.7181e-01, -1.6025e-01,\n",
      "         -2.0980e-01,  2.2996e-01,  8.8242e-02,  2.1366e-02,  3.3899e-01,\n",
      "         -4.0348e-01,  4.5464e-01,  3.9340e-01]], grad_fn=<SliceBackward0>)\n",
      "Loading pre-trained weights for BERT\n",
      "tensor([[-4.1279e-01, -7.1091e-02,  1.3807e-01, -1.6348e-01,  1.8762e-02,\n",
      "          4.8942e-02,  4.5610e-01,  3.8584e-01, -5.4301e-01, -5.7455e-01,\n",
      "         -1.9118e-01,  1.0707e-01,  2.0622e-01,  5.7873e-01,  3.9707e-02,\n",
      "         -3.0273e-02,  1.6496e-02,  4.8725e-01,  1.8920e-01, -4.8741e-01,\n",
      "          3.2928e-01,  3.9907e-02, -9.6873e-04, -5.2008e-02,  6.9975e-02,\n",
      "         -1.1416e-02, -4.7375e-01,  1.7909e-01, -3.4119e-01, -1.2418e-01,\n",
      "         -1.7767e-01, -9.2584e-02,  1.0709e-01,  2.7457e-01,  2.9894e-01,\n",
      "         -4.1085e-01, -2.5719e-01,  5.4164e-02, -1.6168e-01,  2.0928e-01,\n",
      "          1.5174e-01, -1.5680e-01,  6.5122e-02, -1.6503e-01,  4.2753e-02,\n",
      "         -2.7030e-03, -2.5331e+00, -2.0089e-01, -2.1027e-01,  3.8321e-02,\n",
      "         -5.7668e-02, -2.7964e-01,  1.6007e-01,  6.6892e-02, -9.6273e-02,\n",
      "          6.3372e-01,  2.6269e-01,  4.4300e-01,  1.9611e-01,  1.1194e-01,\n",
      "          3.5539e-01, -7.0679e-01, -2.3047e-01, -1.0651e-01,  1.0996e-01,\n",
      "          4.8858e-02, -2.4067e-02,  6.7770e-01, -3.1998e-01,  5.0119e-01,\n",
      "         -8.9436e-02,  5.8437e-02,  2.1917e-01, -4.7519e-02,  8.7713e-02,\n",
      "         -3.5639e-01, -1.6271e-01,  2.6710e-01, -5.0509e-01, -4.2093e-01,\n",
      "         -1.3706e-01,  1.9561e-02,  1.5278e-01, -2.1738e-03,  3.1021e-01,\n",
      "          1.1056e-01, -3.9238e-01, -4.7695e-01, -3.8612e-02,  4.4315e-01,\n",
      "          1.3583e-01, -1.8589e-01, -2.3884e-01,  4.8163e-01,  3.6179e-01,\n",
      "         -3.0803e-01,  5.7660e-02,  1.7379e-01, -2.9819e-01, -3.1656e-02,\n",
      "         -2.7410e-01, -2.4676e-02,  5.6624e-01, -3.0974e-01,  5.0467e-01,\n",
      "          6.3825e-02,  3.2656e-02, -2.8361e-01,  2.5326e-01, -2.1018e+00,\n",
      "          4.8096e-01,  2.1979e-01, -6.6216e-02, -3.1587e-01, -1.5300e-01,\n",
      "          5.1969e-01,  4.4232e-01, -3.0085e-01,  1.9396e-01,  3.2679e-01,\n",
      "         -1.9868e-01,  6.4055e-02, -2.1414e-01, -2.8817e-03,  3.4268e-01,\n",
      "          4.6373e-01, -1.8976e-01, -2.9183e-01,  6.2766e-01, -1.2284e-01,\n",
      "          2.9519e-02,  2.2974e-01, -6.9071e-03, -1.3224e-01, -3.4441e-02,\n",
      "          3.2064e-01,  3.5503e-01, -1.0546e-02,  1.0276e-01, -1.7301e-01,\n",
      "         -5.7471e-01, -2.5189e-01, -2.2857e+00, -5.9666e-02,  9.2236e-01,\n",
      "          3.6574e-01, -5.9065e-01,  4.9328e-01,  3.8324e-01,  1.5430e-01,\n",
      "         -5.9519e-01,  1.7557e-01, -8.9767e-02, -1.3471e-02, -1.6660e-01,\n",
      "         -4.7526e-01,  8.0006e-01, -3.6301e-02,  2.6703e-02,  6.7910e-01,\n",
      "          3.7262e-01, -7.3963e-02, -1.3718e-02,  2.2585e-01, -4.6387e-01,\n",
      "          1.3924e-01,  3.0702e-01,  1.7247e-01,  4.3205e-01, -1.5665e-01,\n",
      "         -2.6878e-01,  7.1712e-02,  4.9163e-01,  8.0485e-02, -2.5441e-02,\n",
      "         -2.8364e-01,  5.2092e-01,  2.0047e-01,  1.1241e-01, -4.1051e-01,\n",
      "         -2.4159e-01,  3.1005e-01, -3.5585e-01, -1.8098e-01,  4.0195e-01,\n",
      "         -9.3366e-03,  1.9003e-01,  4.8090e-02,  9.6280e-03,  1.8359e-01,\n",
      "         -4.0460e-01, -6.0478e-01, -4.0662e-02, -1.2061e-02,  4.1763e-01,\n",
      "          1.2064e-01,  1.2254e-01, -4.4625e-01, -2.1130e-01,  4.1275e-01,\n",
      "          5.8000e-01,  2.9382e-01,  2.7960e-01,  3.4382e-01, -6.8105e-02,\n",
      "          3.1147e+00, -1.9865e-01, -9.5576e-02,  2.4218e-01,  9.0392e-01,\n",
      "         -5.5135e-01,  5.6352e-01,  8.1652e-02,  7.7518e-02,  4.3619e-02,\n",
      "          1.3376e-01,  3.8815e-01, -1.0418e-01, -3.1081e-02,  5.2856e-01,\n",
      "          1.1162e-01, -1.5806e-01,  1.3391e-02,  2.5379e-01, -2.6369e-01,\n",
      "          6.4043e-02,  1.0912e-01,  5.6879e-02, -5.6886e-02, -7.3462e-01,\n",
      "          5.3377e-02, -1.0210e-01, -3.4323e-01,  4.3175e-01,  7.8247e-02,\n",
      "          3.0056e-01, -2.3543e-01, -4.0419e-01, -2.6828e-01,  2.2709e-01,\n",
      "         -1.6443e-01,  5.6933e-02,  5.2786e-01,  2.0561e-01, -3.2931e-01,\n",
      "         -1.7195e-01,  5.6138e-01, -1.2904e-01,  5.5106e-01,  1.8690e-01,\n",
      "          2.5960e-01, -3.8150e-01,  3.9061e-02, -3.2915e-01,  3.1101e-01,\n",
      "          5.8613e-01,  1.0743e-01,  2.0915e-03, -3.1057e-01, -2.0940e-01,\n",
      "         -2.2616e-01, -1.4734e-01,  1.1797e-01, -1.5545e-01, -3.6429e-01,\n",
      "          4.0912e-01,  1.8689e-01, -4.2443e-01,  4.1455e-01, -3.1903e-02,\n",
      "         -2.1231e-01, -1.5641e-01, -1.7312e-01, -2.7876e+00,  1.5547e-01,\n",
      "          2.2938e-01,  7.1588e-01,  2.1127e-01, -1.6443e-01, -2.0927e-01,\n",
      "          2.7911e-01, -1.2875e-01, -3.0656e-01,  2.1930e-01,  5.4691e-02,\n",
      "         -7.5486e-01,  3.3365e-01, -5.8043e-01,  1.3413e-01, -1.8129e-01,\n",
      "         -3.1905e-01, -2.2622e-01,  2.4285e-02,  5.7462e-01,  4.7023e-01,\n",
      "         -2.7884e-01,  1.1344e-01,  2.7585e-01,  1.1320e-01, -2.0121e-01,\n",
      "         -1.1650e-01,  3.4495e-01, -2.2156e-01,  3.7319e-02, -2.6215e-01,\n",
      "          1.9835e-01,  2.4938e-02, -3.6873e-01, -4.5268e+00,  1.2389e-02,\n",
      "         -2.6964e-02, -5.8744e-01,  7.5428e-02,  8.0306e-02,  6.7687e-01,\n",
      "          3.4872e-01,  1.1511e-01, -2.3419e-01,  1.4840e-01, -1.0032e-01,\n",
      "          3.2678e-01,  2.0097e-01, -2.2418e-01, -1.1221e-01,  2.5109e-01,\n",
      "          4.2298e-01, -1.2824e-01,  3.3582e-01, -2.2802e-01,  1.5042e-01,\n",
      "          3.8255e-01, -4.0944e-01, -1.3091e-01,  3.5780e-01, -1.8575e-01,\n",
      "          4.0126e-02, -1.9618e-01, -2.6139e-01,  2.0223e-01, -3.9435e-02,\n",
      "          1.0267e-01, -1.8175e-01, -2.9407e-01,  9.8720e-02,  3.2618e-01,\n",
      "          4.8111e-01,  9.5374e-01,  2.3700e-01,  2.3473e-01,  2.5957e-02,\n",
      "         -2.3123e-01,  4.9025e-01,  1.7530e-01,  4.2134e-03, -3.9969e-01,\n",
      "         -2.0642e-01,  1.1788e-01,  1.2157e-01, -5.9573e-01, -1.1262e-01,\n",
      "          1.0474e+00, -6.9246e-02,  5.5318e-01,  2.9857e-01, -5.5381e-02,\n",
      "          2.0047e-01,  1.1726e-01, -3.4064e-01,  7.8026e-01, -3.4145e-01,\n",
      "          3.9752e-01, -9.7347e-02,  3.0301e-01, -3.5803e-01,  1.9096e-01,\n",
      "         -4.2347e-01, -3.0841e-02,  2.3957e-01, -3.3737e-01, -4.3713e-01,\n",
      "          1.1225e-01, -9.2011e-01,  7.2008e-02,  2.8209e-01, -1.5301e-01,\n",
      "          9.4834e-02,  5.4077e-02, -4.2167e-01, -2.0093e-01,  2.5976e-01,\n",
      "         -7.8375e-02,  7.1507e-01, -2.4574e-01,  1.1422e-01, -1.4382e-01,\n",
      "          2.2692e-02, -1.6633e-01,  1.0444e-01, -2.3738e-01,  2.3233e-01,\n",
      "         -5.0622e-02, -2.3741e-01, -4.3494e-02,  5.0905e-01,  4.9618e-01,\n",
      "         -6.9221e-01, -7.2700e-02, -1.5607e-01,  9.6983e-02, -3.5427e-01,\n",
      "          3.1767e-01, -1.4548e-01, -1.8879e-01, -6.4560e-02, -9.2294e-01,\n",
      "          4.6102e-01,  9.8768e-02,  1.4862e-02,  1.3327e-01, -1.2002e-01,\n",
      "          5.7969e-02,  3.2459e-01,  4.7852e-01, -1.6939e-01, -3.9193e-01,\n",
      "          2.7460e-01, -5.3227e-02,  4.3306e-02,  2.4048e-01, -1.6606e-01,\n",
      "         -2.7672e-01, -9.6779e-02, -1.4292e-01, -1.9970e-01,  6.6435e-02,\n",
      "          3.4894e-01, -1.7492e-01, -3.7321e-01,  3.3259e-02, -2.4820e-02,\n",
      "         -3.0283e-01, -6.6504e-01,  6.5517e-02, -1.5651e-01, -1.8930e-01,\n",
      "         -4.7992e-02,  5.1283e-01,  4.4872e-03,  8.8810e-02, -5.7684e-01,\n",
      "         -5.7091e-01,  5.1089e-01,  1.1542e-01,  4.6748e-01, -4.9359e-01,\n",
      "         -3.3969e-01, -3.2849e-01,  1.8470e-01,  2.2097e-01, -5.4875e-01,\n",
      "          4.7663e-01, -4.5727e-01,  1.0431e-02, -1.9471e-02, -1.1836e-01,\n",
      "          2.1056e-01, -6.3887e-02,  3.9194e-01,  1.7854e-01, -2.7879e-01,\n",
      "         -8.1807e-01,  1.4452e-01, -3.3519e-01, -1.7598e-01,  7.6717e-02,\n",
      "          1.3182e-01, -4.4021e-01,  3.5083e-01, -2.1334e-02, -1.7240e-01,\n",
      "         -1.2608e-01,  1.9648e-01,  5.0339e-03,  6.3062e-01,  1.4420e-02,\n",
      "         -1.7074e-01,  1.8207e-01,  1.6392e-01,  4.1413e-02,  1.4330e-01,\n",
      "          6.0670e-02,  5.0481e-01, -2.0434e-03, -1.9328e-01,  3.2853e-01,\n",
      "          9.9257e-02,  2.4337e-01,  1.0521e-01, -2.8201e-01, -1.4233e-01,\n",
      "          8.2281e-02, -3.8856e-01, -3.9345e-01, -5.5235e-01,  2.9297e-01,\n",
      "          3.5093e-01,  1.1597e-01,  2.6205e-01,  4.4862e-01,  9.3728e-02,\n",
      "         -4.3545e-02,  1.1510e-01,  3.1176e-01,  4.6630e-02,  5.7577e-01,\n",
      "          2.0818e-01,  1.0856e-01,  3.2767e-01,  5.2209e-01, -2.6261e-01,\n",
      "          3.4584e-01, -3.8541e-01, -4.6617e-02, -2.4143e-01,  6.3012e-02,\n",
      "         -7.2243e-02, -1.6428e-01,  1.2998e-02, -2.1852e-01, -5.9741e-01,\n",
      "         -3.7518e-02,  3.6566e-02, -2.8653e-01,  3.1675e-01, -3.7721e-01,\n",
      "         -6.1277e-01,  2.9729e-01, -1.8129e-01, -2.9495e-02,  2.3154e-01,\n",
      "          3.8163e-01,  3.8434e-02,  3.2675e-02, -7.4505e-01, -9.0394e-01,\n",
      "          2.3106e-02, -1.4342e-01,  4.4015e-01,  4.0328e-02, -1.8483e-01,\n",
      "          4.6706e-02, -8.7847e-01, -1.6932e-01,  4.3191e-01,  2.3382e-01,\n",
      "         -2.6179e-01,  2.8894e-01,  5.5765e-01,  1.8498e-01,  3.0790e-02,\n",
      "         -1.6550e-01, -1.9809e-01,  1.7402e-01, -2.1198e-01, -6.0609e-01,\n",
      "         -2.2377e-01, -1.0979e-01,  5.1984e-01, -4.1343e-01,  2.4564e-01,\n",
      "         -3.0583e-01,  3.6215e-01,  5.1035e-01,  4.2768e-01,  2.8228e-02,\n",
      "          2.7532e-01,  3.6520e-01,  3.5264e-01, -3.1064e-01,  1.7084e-01,\n",
      "         -3.5616e-02,  5.0398e-02, -8.8747e-02,  2.9806e-01, -2.6444e-01,\n",
      "          1.3814e-01,  3.4714e-01, -3.7069e-01,  1.5595e+00,  4.3492e-01,\n",
      "         -3.1404e-01, -2.9756e-02,  5.6969e-01, -2.6690e-01, -4.1859e-01,\n",
      "         -5.4777e-01, -5.2123e-01,  2.6754e-01,  1.5880e-02,  3.0940e-01,\n",
      "          1.0548e-01,  3.1401e-01,  3.8694e-01,  4.0845e-01, -1.6792e-01,\n",
      "         -2.1133e-01, -7.1808e-01,  1.1958e-01, -3.9343e-01,  5.2976e-01,\n",
      "          5.4291e-01, -6.6981e-01,  1.0998e-01,  1.7673e-01,  1.1272e-01,\n",
      "         -2.5973e-01,  5.4390e-03, -2.7134e-02,  4.6848e-02, -1.4480e-01,\n",
      "          2.3569e-01,  5.3794e-01, -4.7673e-02,  2.2482e-01,  1.0127e-01,\n",
      "         -2.6972e-01, -5.9087e-01, -4.4728e-02,  6.8620e-02, -2.8296e-01,\n",
      "          5.1246e-01, -1.0240e-01, -1.6581e-01,  5.0803e-01, -5.6296e-01,\n",
      "         -1.0912e-01,  1.0276e-02, -2.1161e-02, -1.1355e-01, -1.0709e-01,\n",
      "         -3.1120e-01, -1.3840e-01, -9.4295e-02, -3.7851e-01, -1.1332e-01,\n",
      "         -2.9076e-01, -1.5454e-01,  4.2683e-01,  2.2686e-01,  3.6318e-01,\n",
      "          1.7530e-01, -1.6564e-01, -6.8977e-03, -1.2528e-01, -3.5780e-01,\n",
      "          3.3353e-01,  5.6056e-01,  6.1249e-01,  2.1107e-02,  2.2409e-01,\n",
      "          5.7931e-01,  7.8049e-03,  1.1965e-01,  1.4475e-01,  3.1181e-01,\n",
      "         -3.0924e-01, -2.8857e-01, -2.4864e+00, -2.1158e-01, -1.1414e-01,\n",
      "          5.6969e-01, -2.9841e-02,  2.8235e-01, -1.7566e-03,  1.5729e-01,\n",
      "          1.3002e-02, -1.2855e-01,  8.4433e-02,  4.5202e-01, -4.5970e-02,\n",
      "         -1.4382e-01,  2.6832e-01, -2.3216e-01,  2.6935e-01, -4.5311e-01,\n",
      "         -1.8343e-01, -5.9220e-02,  5.8515e-03,  4.0505e-02, -1.1954e-01,\n",
      "          3.5307e-01, -2.6587e-01,  3.3780e-01,  1.4998e-01, -3.0818e-01,\n",
      "         -1.7319e-02, -2.8185e-02, -4.1676e-01, -1.2134e-01, -2.3112e-01,\n",
      "         -6.5343e-02,  8.8976e-02, -3.3150e-01,  4.8805e-02,  1.0375e-04,\n",
      "          1.2112e-01,  4.2929e-01,  2.9030e-01,  5.5207e-01, -8.7353e-02,\n",
      "          4.5823e-01, -2.7284e-01, -2.5429e-02,  2.3561e-01, -2.1170e-01,\n",
      "          4.8073e-01,  8.7434e-02,  2.5988e-01, -1.5377e-01,  1.2468e-01,\n",
      "         -2.5412e-01, -6.3050e-02,  1.8218e-01, -1.6314e-01,  3.8369e-02,\n",
      "          6.6321e-02, -2.3408e-01, -1.3797e-01, -1.6731e-01, -1.7926e-01,\n",
      "          2.6684e-01,  3.8503e-01, -3.5230e-01,  6.7742e-02, -2.7298e-01,\n",
      "          3.7798e-02, -7.2483e-03, -1.0018e-01, -3.0228e-01,  3.9816e-01,\n",
      "          6.1276e-02, -2.6289e-01,  2.7447e-01,  3.3706e-01,  7.1220e-02,\n",
      "         -2.6751e-01,  1.2496e-01, -3.5530e-01, -4.4677e-01,  1.5147e-01,\n",
      "         -6.4531e-02,  3.5861e-01, -6.3076e+00, -4.5282e-01,  1.1718e-01,\n",
      "         -1.7032e-01, -4.0973e-02, -7.1339e-01,  1.7175e-01, -1.6011e-01,\n",
      "         -2.0991e-01,  2.3039e-01,  8.8038e-02,  2.1827e-02,  3.3925e-01,\n",
      "         -4.0319e-01,  4.5485e-01,  3.9352e-01]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/varun/projects/experiments-with-gpt2/\")\n",
    "\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from bert import BERT\n",
    "from bert_config import BERTConfig\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_hf = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text_1 = \"Hello,world\"\n",
    "text_2 = \"Second sentence\"\n",
    "encoded_input = tokenizer(text_1,text_2,return_tensors=\"pt\")\n",
    "print(encoded_input)\n",
    "output_hf = model_hf(**encoded_input)\n",
    "embedding_output = model_hf.embeddings(encoded_input[\"input_ids\"])\n",
    "encoder_output = model_hf.encoder(embedding_output)\n",
    "# print(encoder_output)\n",
    "# print(output_hf)\n",
    "print(output_hf.last_hidden_state[:,0,:])\n",
    "\n",
    "model = BERT.from_pretrained(config=BERTConfig())\n",
    "output = model(**encoded_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/projects/experiments-with-gpt2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained weights for BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_496195/562803406.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_masks_padded = torch.tensor(attention_masks_padded,dtype=torch.bool)\n",
      "68671it [21:56, 52.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Store the embeddings for the dev set\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home/varun/projects/experiments-with-gpt2/\")\n",
    "\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from bert import BERT\n",
    "from bert_config import BERTConfig\n",
    "from rag.snliDataset import snliDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = BERT.from_pretrained(config=BERTConfig())\n",
    "device=\"cuda\"\n",
    "model.to(device)\n",
    "def dynamic_padding(data):\n",
    "    input_ids = [item[\"input_ids\"][0] for item in data]\n",
    "    attention_masks = [item[\"attention_mask\"][0] for item in data]\n",
    "    token_type_ids = [item[\"token_type_ids\"][0] for item in data]\n",
    "    inputs_padded = pad_sequence(input_ids,batch_first=True,padding_value=0)\n",
    "    attention_masks_padded = pad_sequence(attention_masks,batch_first=True,padding_value=0)\n",
    "    attention_masks_padded = torch.tensor(attention_masks_padded,dtype=torch.bool)\n",
    "    token_type_ids_padded = pad_sequence(token_type_ids,batch_first=True,padding_value=0)\n",
    "    return {\"input_ids\": inputs_padded, \"attention_masks\": attention_masks_padded,\"token_type_ids\": token_type_ids_padded}\n",
    "\n",
    "sd = snliDataset(\"train\")\n",
    "batch_size = 8\n",
    "dl = DataLoader(sd,batch_size=batch_size,collate_fn=dynamic_padding)\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(dl)):\n",
    "        output = model(batch[\"input_ids\"].to(device),\n",
    "                    batch[\"token_type_ids\"].to(device),\n",
    "                    batch[\"attention_masks\"].to(device))\n",
    "        output = output.cpu()\n",
    "        embeddings.append(output)\n",
    "\n",
    "embeddings = torch.cat(embeddings,dim=0)\n",
    "torch.save(embeddings, \"embeddings_train.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a MLP classifier\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size,hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size,output_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.dropout(F.relu(self.hidden_layer(x)))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/projects/experiments-with-gpt2/rag/snliDataset.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings_mat = torch.load(f\"embeddings_{split}.pt\")\n",
      "/tmp/ipykernel_500154/3408953647.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = criterion(outputs,torch.tensor(batch[\"label\"]).to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7873\n",
      "Epoch [2/10], Loss: 0.7325\n",
      "Epoch [3/10], Loss: 0.7154\n",
      "Epoch [4/10], Loss: 0.7044\n",
      "Epoch [5/10], Loss: 0.6944\n",
      "Epoch [6/10], Loss: 0.6878\n",
      "Epoch [7/10], Loss: 0.6814\n",
      "Epoch [8/10], Loss: 0.6765\n",
      "Epoch [9/10], Loss: 0.6715\n",
      "Epoch [10/10], Loss: 0.6678\n"
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/home/varun/projects/experiments-with-gpt2/\")\n",
    "\n",
    "from snliDataset import snliDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "\n",
    "sd = snliDataset(split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "mlp = MLP(768,100,3)\n",
    "mlp.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(mlp.parameters(),lr=learning_rate)\n",
    "n_epochs = 20\n",
    "train_loader = DataLoader(sd,batch_size=32)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    mlp.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i,batch in enumerate(train_loader):\n",
    "        outputs = mlp(batch[\"embedding\"].to(device))\n",
    "        loss = criterion(outputs,torch.tensor(batch[\"label\"]).to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.19%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "mlp.eval()\n",
    "correct, total = 0, 0\n",
    "sd = snliDataset(split=\"test\")\n",
    "test_loader = DataLoader(sd,batch_size=32)\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        outputs = mlp(batch[\"embedding\"].to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # print(predicted, batch[\"label\"])\n",
    "        total += batch[\"label\"].size(0)\n",
    "        correct += (predicted == batch[\"label\"].to(device)).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9842, 768])\n",
      "tensor([-8.3870e-02, -2.0120e-01,  2.8359e-01,  8.3558e-02,  1.5864e-01,\n",
      "        -3.3191e-01,  1.8555e-02,  3.4614e-01, -1.2018e-01, -5.8454e-02,\n",
      "         1.5888e-01, -7.4928e-02, -1.1119e-01,  2.8032e-01, -4.3628e-02,\n",
      "         1.0782e-01, -2.3436e-01,  2.5837e-01,  5.0681e-02,  2.0824e-01,\n",
      "         2.3817e-01, -2.7823e-01, -1.1665e-01,  1.1745e-01,  1.8096e-01,\n",
      "        -1.6913e-01, -1.4109e-01,  2.0160e-02,  7.0707e-02, -2.0918e-01,\n",
      "         2.5349e-01,  1.3314e-01, -5.6560e-02, -1.0323e-01,  1.1722e-01,\n",
      "        -5.7964e-03,  1.4605e-02, -5.4307e-02, -6.8620e-02,  1.0881e-01,\n",
      "        -3.0531e-01, -3.0762e-01,  9.1356e-02,  1.3269e-01, -1.8626e-01,\n",
      "        -4.8844e-01,  4.4068e-01,  1.9068e-02, -7.5594e-02,  1.2931e-01,\n",
      "        -1.0715e-01,  1.6343e-01,  3.5730e-02,  2.6090e-03,  2.4221e-01,\n",
      "         5.0100e-01, -3.6525e-01, -1.7202e-01, -1.9746e-01, -2.0829e-01,\n",
      "         7.8090e-02, -3.6817e-02,  2.4409e-01, -3.0138e-01, -1.5168e-02,\n",
      "         9.8411e-02, -1.2998e-01,  3.8705e-01, -4.3174e-01,  4.9228e-03,\n",
      "        -1.0862e-01, -2.2093e-01,  2.2568e-02, -6.7598e-03, -3.0915e-01,\n",
      "         2.5228e-01, -6.4475e-02,  8.5611e-03,  7.0507e-02, -3.1935e-01,\n",
      "        -3.4578e-01,  2.4617e-01, -1.9298e-01,  4.9459e-01, -1.1548e-02,\n",
      "        -4.7355e-02, -2.4295e-01, -1.1480e-02, -2.4985e-01,  2.6959e-01,\n",
      "        -7.6763e-02,  9.0630e-02,  6.2023e-02,  1.6818e-01, -7.4688e-02,\n",
      "         2.4908e-01,  1.3730e-01,  3.0516e-01, -6.9130e-02,  2.8485e-01,\n",
      "         2.4402e-01, -1.0200e-01, -7.2567e-02,  1.2665e-01, -8.1006e-02,\n",
      "        -2.4942e-01, -3.0101e-02, -4.8811e-02,  4.1685e-01,  9.9510e-03,\n",
      "         9.1840e-02, -1.3944e-01,  2.1024e-01, -3.1437e-03,  3.3132e-02,\n",
      "         1.1073e-02,  1.2238e-01, -4.2271e-01, -2.1087e-01,  1.2152e-01,\n",
      "        -4.9046e-02, -1.3562e-01,  4.4132e-02,  5.2333e-01,  2.8067e-02,\n",
      "         1.4397e-01, -1.5014e-01,  7.8450e-02, -1.3147e-01, -6.4914e-02,\n",
      "        -4.5586e-02,  2.4776e-01,  1.7941e-01, -4.4349e-01, -2.6264e-01,\n",
      "         1.0683e-02,  4.5948e-02, -1.6506e-01, -5.5742e-02,  7.9056e-02,\n",
      "        -7.8592e-02,  9.9559e-02,  3.9124e-01,  7.5668e-02,  1.6216e-01,\n",
      "        -3.8729e-02, -3.1502e-02,  1.0844e-01, -1.0951e-01,  7.5116e-02,\n",
      "         1.5465e-01,  1.4855e-02,  2.2535e-02, -7.2924e-02,  9.6010e-02,\n",
      "         4.0407e-02, -1.5611e-01,  1.3271e-02,  5.5799e-02,  4.2763e-02,\n",
      "         1.4600e-01,  1.1612e-02, -1.2223e-02,  2.4724e-01,  7.5302e-02,\n",
      "         1.6070e-01, -1.5286e-02,  3.6777e-01, -1.0641e-01,  2.8580e-01,\n",
      "        -1.1011e-01, -4.0236e-02,  1.8799e-01, -1.4495e-01, -2.1278e-01,\n",
      "         2.7477e-02,  4.1110e-02, -5.8434e-02,  8.3181e-02, -6.9794e-03,\n",
      "        -8.1924e-01,  3.1263e-01,  1.2188e-01, -6.7071e-02,  1.2438e-01,\n",
      "        -3.2409e-01, -1.3876e-01,  2.8164e-05, -1.0164e-01,  9.0265e-02,\n",
      "        -8.5870e-02,  3.0947e-02, -1.6833e-01,  9.0363e-02, -5.2515e-02,\n",
      "         3.8537e-03, -2.2823e-01, -8.6321e-02, -3.0288e-01, -5.1360e-03,\n",
      "         7.7480e-02,  4.0981e-02,  2.9917e-01,  3.2350e-01, -1.3994e-02,\n",
      "         1.3374e-01,  9.4269e-02, -1.7858e-01,  1.9381e-01,  2.0215e-01,\n",
      "        -4.6628e-01,  4.1524e-01,  6.2615e-02,  1.3684e-01, -3.3152e-01,\n",
      "        -2.4590e-01,  1.2430e-01, -8.9432e-02, -8.0119e-02, -1.7018e-01,\n",
      "        -2.2480e-01,  1.5498e-01, -3.6747e-01,  2.8211e-01,  2.6557e-01,\n",
      "         4.4381e-01,  1.9517e-01, -1.1304e-01, -1.4076e-01,  3.6078e-01,\n",
      "         2.6661e-02, -2.6891e-01,  1.7978e-01,  1.0179e-01, -1.6880e-01,\n",
      "         8.2297e-02, -7.8112e-02, -4.2318e-02, -2.4796e-02, -4.8398e-01,\n",
      "        -2.5642e-01,  4.7760e-02,  3.0759e-01, -6.8548e-02,  3.4176e-02,\n",
      "        -1.7411e-01, -7.5503e-02,  1.1447e-01, -2.3596e-01, -1.1778e-01,\n",
      "        -1.6878e-01, -1.9459e-01, -2.3260e-02, -4.4998e-01, -1.0953e-01,\n",
      "        -1.6292e-01,  6.8976e-03, -1.9845e-02,  1.8317e-01, -5.9441e-02,\n",
      "         5.8665e-02, -2.3321e-03,  2.1389e-01,  1.9131e-01, -6.1751e-01,\n",
      "        -3.3363e-01,  2.4534e-01,  4.7505e-02,  1.4702e-04, -6.0613e-02,\n",
      "         4.5845e-02, -1.4889e-01,  2.9966e-02,  3.9222e-01, -1.7349e-01,\n",
      "        -4.2072e-01,  2.3427e-01,  5.0178e-02, -1.1156e-01, -1.5404e-01,\n",
      "         3.4034e-01,  2.5893e-01, -1.5669e-01, -1.0667e-01,  1.8742e-01,\n",
      "        -2.2102e-01, -1.6138e-02,  5.3902e-02, -2.1795e-01, -3.5668e-01,\n",
      "        -1.0243e-02,  2.4302e-01, -2.3884e-01,  2.2980e-02,  1.9121e-01,\n",
      "        -1.6403e-01, -1.0766e-01,  3.0359e-01,  4.0195e-01,  1.7774e-02,\n",
      "        -2.3858e-01,  2.0217e-01, -6.4505e-02,  2.9156e-01, -2.3401e-01,\n",
      "         8.6676e-02,  1.2228e-01, -4.4283e-01, -4.8056e+00,  2.7878e-01,\n",
      "        -6.9039e-02, -1.5430e-01,  3.1530e-01, -1.7655e-01,  1.0382e-01,\n",
      "        -2.8381e-01, -3.7733e-01,  2.9067e-01, -1.9056e-01, -2.0276e-01,\n",
      "         7.6139e-02,  1.7033e-01,  1.0806e-01,  8.1557e-02, -2.3311e-02,\n",
      "        -2.1846e-01,  5.5423e-02,  3.2324e-01, -1.5542e-01, -3.8757e-01,\n",
      "         2.2320e-01, -7.7961e-02,  3.9465e-01,  3.4837e-01,  1.4205e-01,\n",
      "         4.5335e-02,  7.7921e-02, -1.2278e-01,  4.1854e-02, -1.4698e-02,\n",
      "         1.9363e-02, -3.3282e-01, -5.9722e-02, -8.4548e-02,  1.8324e-01,\n",
      "        -3.7340e-01, -1.4654e-01, -2.1468e-01, -1.3359e-01, -2.2696e-01,\n",
      "         1.8240e-02,  1.2641e-01,  5.8033e-01,  9.6092e-02, -2.6991e-01,\n",
      "        -3.6248e-01, -2.8527e-02,  6.2448e-02,  4.0427e-01,  3.2989e-02,\n",
      "        -3.3324e-01, -7.4101e-02, -5.6268e-02, -1.3797e-01,  8.8783e-02,\n",
      "         2.1410e-01, -1.7802e-02, -3.9374e-01, -2.7040e-01, -2.0104e-02,\n",
      "        -2.9019e-01, -3.4447e-02,  1.3590e-01, -2.6057e-01, -1.9076e-01,\n",
      "        -7.8826e-02, -3.0248e-01, -3.2997e-03, -7.2373e-04,  1.6721e-02,\n",
      "        -3.9085e-01, -5.3178e-01,  2.5076e-01, -1.6362e-01,  3.0619e-01,\n",
      "         5.8265e-02,  2.7738e-01,  3.2463e-02,  1.0854e-01, -1.7007e-01,\n",
      "         3.3249e-02, -3.0623e-01,  5.7964e-02, -2.6986e-01, -1.1245e-03,\n",
      "        -1.8481e-01, -1.7418e-01, -3.5052e-01,  1.1164e-01,  2.4707e-01,\n",
      "         9.5896e-02, -1.3113e-02,  7.7787e-03, -4.6079e-02,  1.4538e-01,\n",
      "         2.4194e-01,  3.0068e-01, -3.5438e-01, -5.7913e-02, -4.1000e-02,\n",
      "         5.3231e-01, -8.7424e-02,  7.8882e-02, -1.0182e-01, -2.0263e-01,\n",
      "         9.2535e-02, -1.9413e-01, -2.5288e-02,  1.5848e-01, -6.2883e-01,\n",
      "         4.5056e-01, -2.8330e-02, -1.7932e-01, -1.2843e-01,  1.3216e-01,\n",
      "         5.1059e-01, -1.0474e-01, -6.7126e-03, -1.6659e-02,  4.7063e-01,\n",
      "        -1.5806e-01, -4.2585e-01, -3.6901e-01, -2.5700e-01, -2.3357e-01,\n",
      "        -2.5162e-01, -1.4749e-01,  9.7765e-03, -1.0172e-01, -2.1987e-01,\n",
      "        -8.5371e-02, -2.4325e-02,  3.9232e-01,  7.9782e-03, -1.6262e-01,\n",
      "        -7.3502e-01, -9.3915e-02, -3.2226e-02,  2.0664e-01,  1.1226e-01,\n",
      "        -2.0570e-01, -1.3334e-01,  6.2889e-02,  4.2423e-01, -2.6472e-01,\n",
      "        -2.1146e-01, -3.0713e-01,  1.8842e-02, -2.4401e-01, -3.0507e-01,\n",
      "         1.0274e-01, -2.4964e-01,  6.9797e-02, -7.5595e-02,  3.7459e-01,\n",
      "         1.8662e-01, -9.4897e-02, -3.0856e-01, -1.7709e-01,  8.3812e-02,\n",
      "         2.1642e-01,  1.7483e-01, -2.8715e-01,  9.3361e-02,  1.3770e-01,\n",
      "        -1.8442e-01, -4.7223e-01,  3.6729e-01,  9.5679e-02, -2.4072e-01,\n",
      "        -1.6607e-01,  8.5100e-03, -3.0573e-01,  1.9798e-01,  3.8247e-01,\n",
      "        -1.3858e-01, -1.3065e-01,  8.3569e-02, -1.5017e-01, -2.1998e-01,\n",
      "        -1.0898e-01, -1.4018e-01,  1.5808e-01,  1.2073e-01,  7.8850e-02,\n",
      "         1.8774e-01, -8.7550e-03,  7.5630e-02, -1.3521e-01,  3.2946e-01,\n",
      "         5.1845e-03,  5.2801e-02, -1.2147e-01, -3.8754e-01,  3.1751e-01,\n",
      "         2.9314e-02, -1.0164e-01,  2.4030e-01,  3.8071e-02, -1.6198e-01,\n",
      "        -1.5852e-02,  3.5057e-02,  6.0645e-02, -4.5707e-01,  8.4672e-02,\n",
      "         3.3540e-02, -9.2698e-02,  3.3305e-02, -2.2981e-02, -2.9656e-02,\n",
      "         3.5661e-02, -7.9394e-02,  8.4605e-02, -9.3698e-02,  9.0077e-02,\n",
      "        -2.5235e-02,  7.7075e-02,  1.3048e-01, -3.1542e-01, -1.3904e-02,\n",
      "        -2.0144e-02, -1.9437e-01, -5.6989e-01, -2.6218e-01,  2.3429e-01,\n",
      "         3.9022e-02, -9.5518e-02, -6.6379e-02,  5.3217e-02, -3.1477e-01,\n",
      "         1.9929e-01,  2.8459e-01,  2.9621e-01,  2.7299e-01, -1.1232e-02,\n",
      "        -3.6022e-01,  2.3088e-01,  5.7848e-02, -3.3620e-01, -5.5377e-02,\n",
      "         1.9615e-01, -1.3345e-01,  4.3123e-01,  1.7202e-01,  2.8376e-01,\n",
      "         1.0581e-01, -1.5254e-01,  1.9674e-01, -2.3736e-01,  7.1106e-02,\n",
      "        -1.1269e-01, -4.3571e-01, -1.3440e-02, -1.5595e-01, -2.8997e-01,\n",
      "         3.8271e-02, -8.0035e-02, -1.9732e-02,  3.8560e-02, -1.5103e-01,\n",
      "         4.3649e-02,  1.6201e-01,  3.7519e-01,  2.3199e-01,  8.5952e-02,\n",
      "         1.8900e-01, -6.0209e-02,  2.0027e-01,  4.1669e-02, -4.3969e-02,\n",
      "         3.2048e-01, -4.8683e-01, -1.8758e-02,  1.7573e-01,  1.7446e-01,\n",
      "        -4.5251e-01, -2.2150e-01, -3.9638e-01, -1.4275e-01,  1.6738e-03,\n",
      "        -1.0082e-01, -3.1944e-02,  2.4194e-01, -1.2413e-01, -3.0180e-02,\n",
      "         4.3543e-01, -2.2126e-02, -2.3925e-02, -3.0971e-02,  2.9157e-01,\n",
      "        -1.4522e-01,  2.1608e-01,  3.6846e-01,  1.3757e-01,  4.1107e-01,\n",
      "        -5.8295e-02, -6.0247e-02,  1.6857e-01, -3.2268e-01,  5.9088e-02,\n",
      "        -2.0651e-01,  1.2666e-01,  4.6007e-03,  1.7005e-01, -3.1186e-02,\n",
      "        -3.2986e-01,  3.2286e-02,  3.4434e-01, -3.6047e-01,  1.7887e-02,\n",
      "         2.5538e-01,  2.5131e-01, -1.3233e-01, -1.1255e-01,  1.2709e-01,\n",
      "        -4.5837e-01, -1.8833e-01,  2.4591e-01, -6.7879e-02, -8.3370e-02,\n",
      "         3.0023e-01, -2.9104e-01,  6.1955e-02,  3.6859e-01,  2.3474e-03,\n",
      "         2.4057e-02,  8.9213e-02,  2.6422e-01, -1.4677e-01,  1.7900e-01,\n",
      "        -1.7533e-01,  1.2718e-02,  2.2143e-01, -1.3560e-01,  1.5968e-01,\n",
      "         9.8079e-02, -5.1478e-02, -3.0814e-03, -3.7881e-02,  2.5298e-01,\n",
      "        -3.7624e-02,  1.5295e-01,  9.5228e-02,  3.1034e-01,  1.0928e-01,\n",
      "         3.7241e-01,  3.5319e-01,  1.3571e-01,  2.0609e-01,  4.5284e-01,\n",
      "         7.2934e-02, -1.6392e-01,  2.1758e-01,  1.8989e-01, -2.3160e-02,\n",
      "         2.4434e-01, -5.4153e-02,  4.7769e-01, -4.0256e-03,  2.4369e-01,\n",
      "         2.3692e-01, -2.3913e-01,  1.6274e-02, -1.0256e-01, -7.6543e-02,\n",
      "        -6.4166e-02, -2.0010e-01,  1.2793e-01,  3.2113e-01,  2.4878e-01,\n",
      "        -2.3070e-01, -7.6841e-02, -1.8365e-01,  5.2508e-01, -1.2303e-01,\n",
      "         1.2320e-01, -2.4021e-01,  4.3235e-01, -1.3166e-01, -2.8545e-02,\n",
      "        -2.2558e-01, -1.2535e-02,  4.5578e-02,  1.2050e-01, -2.4127e-01,\n",
      "         5.1205e-02,  1.5810e-02, -2.0083e-02,  1.9314e-01, -2.4679e-02,\n",
      "         4.3158e-01, -1.0493e-01, -4.2865e-02, -1.1817e-01,  3.4771e-01,\n",
      "         3.8268e-01,  4.2727e-01,  1.5120e-01, -4.9551e-02, -2.9787e-02,\n",
      "         1.9755e-02, -1.3997e-01, -2.1057e-01, -6.1848e-02,  9.8250e-02,\n",
      "         1.2568e-01, -4.1636e-01,  1.6858e-02,  3.9940e-02, -8.1860e-02,\n",
      "        -4.7526e-01,  2.4154e-02, -2.1064e-01, -5.2266e-02, -1.4917e-01,\n",
      "         1.3353e-01, -2.2997e-01, -1.5697e-01, -2.4013e-02, -3.2649e-01,\n",
      "        -9.4967e-02,  1.3442e-01, -2.8492e-01,  2.9546e-01, -4.7301e-02,\n",
      "         2.6569e-01, -8.4522e-03,  5.8565e-02,  2.2234e-01,  2.0170e-01,\n",
      "         2.4023e-01, -1.4216e-01,  6.2987e-02, -4.5964e-02, -3.4600e-01,\n",
      "         1.8884e-01, -2.7202e-01,  1.2257e-01,  6.0307e-01, -1.2675e-01,\n",
      "         2.6171e-01,  1.4565e-01,  1.8798e-01, -2.7063e-01, -2.8310e-01,\n",
      "        -5.8417e-02, -9.8900e-02, -1.7016e-01, -1.4295e-01, -3.8326e-01,\n",
      "        -6.2393e-02,  9.9183e-02, -2.6784e-01,  4.2931e-02,  4.1366e-02,\n",
      "        -1.2051e-01, -4.8299e-02, -8.8175e-02])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_500154/1158301358.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  emb_mat = torch.load(\"embeddings_dev.pt\")\n"
     ]
    }
   ],
   "source": [
    "emb_mat = torch.load(\"embeddings_dev.pt\")\n",
    "print(emb_mat.size())\n",
    "print(emb_mat[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
