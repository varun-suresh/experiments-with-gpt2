{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG\n",
    "\n",
    "Build a simple Retrieval-Augmented Generation pipeline to demonstrate its working.\n",
    "\n",
    "Steps:\n",
    "1. Creating a knowledge base : Use the sentence BERT model to convert the document into a list of embeddings.\n",
    "2. Creating an index : Using FAISS (Facebook AI similarity search) library, create an index that can be queried for its nearest neighbors\n",
    "3. Retrieval: Given a query, encode it and return the most similar embeddings from the knowledge base\n",
    "4. Generation: Use GPT-2 for generating a response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Knowledge Base\n",
    "\n",
    "To build out a simple RAG, use a few text documents as the knowledge base.\n",
    "Run sentence BERT on these documents, on overlapping blocks of text and store the vectors.\n",
    "Accept a query from the user\n",
    "Run sentence BERT on the query, retrieve the \"K\" most relevant embeddings from the knowledge base using L2 distance (FAISS)\n",
    "Provide the user query, retrieved embeddings to GPT-2 and generate a response.\n",
    "\n",
    "\n",
    "For the knowledge base, I copied the text about Tour de France from Wikipedia and saved it in a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1743987/3278462792.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained weights for bert\n",
      "Loading pre-trained weights for gpt2\n",
      "Number of parameters: 123.65M\n"
     ]
    }
   ],
   "source": [
    "from rag import RAG\n",
    "import torch\n",
    "from sentenceBERT import sentenceBERT\n",
    "from bert_config import BERTConfig\n",
    "from gpt import GPT\n",
    "from gpt_config import GPTConfig\n",
    "\n",
    "device = \"cuda\"\n",
    "ckpt_path = \"out/bert_ckpt_train.pt\"\n",
    "ckpt = torch.load(ckpt_path)\n",
    "embedding_model_config = BERTConfig()\n",
    "embedding_model = sentenceBERT(embedding_model_config)\n",
    "embedding_model.to(device)\n",
    "\n",
    "generate_model = GPT.from_pretrained(GPTConfig(block_size=1024,use_lora=False))\n",
    "generate_model.to(device)\n",
    "embedding_model_size = embedding_model_config.embedding_size\n",
    "sentence_size = 3\n",
    "overlap_size = 1\n",
    "k = 5\n",
    "\n",
    "rag = RAG(embedding_model,embedding_model_size,generate_model,sentence_size,overlap_size,k)\n",
    "docs = [\"tdf.txt\"]\n",
    "rag.add_to_knowledge_base(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Tell me about the yellow jersey, Response:  This was the last rider to wear the yellow jersey. Tell me about the red lantern Greeting: After many years, the team organizer at this time, Jean-Pierre Rolland, introduced the yellow and red light as a symbol of solidarity.\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about the yellow jersey\"\n",
    "response = rag.get_response(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
