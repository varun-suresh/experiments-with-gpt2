{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cifar10 import cifar10\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "import random\n",
    "dataset = cifar10(\"train\")\n",
    "# mean_img = torch.zeros((3,32,32))\n",
    "# for item in dataset:\n",
    "#     img = item[\"img\"]\n",
    "\n",
    "#     # plt.imshow(img)\n",
    "#     # plt.show()\n",
    "#     img = pil_to_tensor(img)\n",
    "#     mean_img += img\n",
    "#     # print(img.size())\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.7699728..1.7390381].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4914, 0.4822, 0.4465])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0641, -0.2192, -0.7038,  ...,  0.4787,  0.0000,  0.0000],\n",
      "         [-0.0059,  0.1491, -0.0835,  ..., -0.1223,  0.0000,  0.0000],\n",
      "         [-0.5487, -0.5487, -0.3549,  ..., -0.1223,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0580, -0.2154, -0.6874,  ...,  0.5320,  0.0000,  0.0000],\n",
      "         [ 0.0403,  0.1976, -0.0777,  ..., -0.0974,  0.0000,  0.0000],\n",
      "         [-0.4710, -0.4710, -0.3530,  ..., -0.0777,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.1977,  0.0416, -0.4266,  ...,  0.8221,  0.0000,  0.0000],\n",
      "         [ 0.2758,  0.4709,  0.2367,  ...,  0.1782,  0.0000,  0.0000],\n",
      "         [-0.1925, -0.1925, -0.0949,  ...,  0.1197,  0.0000,  0.0000]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_idx = random.sample(range(len(dataset)),k=16)\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for i , idx in enumerate(rand_idx):\n",
    "\n",
    "  img , label = dataset[idx]\n",
    "\n",
    "  #the image tensor's range is not between 0 and 1,so we have to temporarily scale the tensor values into range 0 and 1 to prevent error.\n",
    "  img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "  img_class = class_names[label]\n",
    "\n",
    "  plt.subplot(4,4,i+1)\n",
    "  plt.imshow(img.permute(1,2,0))\n",
    "  plt.title(f\"Class : {img_class}\",fontsize=10)\n",
    "  plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from cifar10 import cifar10\n",
    "from resnet_config import ResNetConfig, ResNetTrainConfig\n",
    "all_train_data = cifar10(\"train\")\n",
    "train_size = int(0.9*len(all_train_data))\n",
    "val_size = len(all_train_data) - train_size\n",
    "test_set = cifar10(\"test\")\n",
    "train_set, val_set = random_split(all_train_data,[train_size,val_size])\n",
    "train_config = ResNetTrainConfig()\n",
    "model_config = ResNetConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/projects/experiments-with-gpt2/vision_models/train.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.ckpt = torch.load(ckpt_path, map_location=self.train_config.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of parameters in the model: 272464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42000 [00:00<?, ?it/s]/home/varun/projects/experiments-with-gpt2/vision_models/train.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_loss += self.criterion(train_logits,torch.tensor(train_batch[\"label\"]).to(self.train_config.device))\n",
      "/home/varun/projects/experiments-with-gpt2/vision_models/train.py:148: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(batch[\"label\"]).to(self.train_config.device)\n",
      "  0%|          | 1/42000 [00:12<151:07:51, 12.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:86000\n",
      "Train Loss:0.31341317296028137\n",
      "Validation Loss:0.30075037479400635\n",
      "Test Error:0.14030003547668457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1998/42000 [01:42<29:45, 22.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:88000\n",
      "Train Loss:0.2926238477230072\n",
      "Validation Loss:0.30841484665870667\n",
      "Test Error:0.1323000192642212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2001/42000 [01:56<15:01:56,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3999/42000 [03:37<28:46, 22.01it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:90000\n",
      "Train Loss:0.3191036581993103\n",
      "Validation Loss:0.31924325227737427\n",
      "Test Error:0.13260000944137573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4001/42000 [03:39<15:46:33,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 5999/42000 [05:20<26:52, 22.33it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:92000\n",
      "Train Loss:0.3317740261554718\n",
      "Validation Loss:0.3643094301223755\n",
      "Test Error:0.1381000280380249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 6001/42000 [05:21<14:54:59,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 7999/42000 [06:51<25:58, 21.82it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:94000\n",
      "Train Loss:0.3082822263240814\n",
      "Validation Loss:0.38767507672309875\n",
      "Test Error:0.14090001583099365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 8002/42000 [07:05<12:52:54,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10000/42000 [08:34<24:15, 21.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:96000\n",
      "Train Loss:0.3151918053627014\n",
      "Validation Loss:0.3523828089237213\n",
      "Test Error:0.13210004568099976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10001/42000 [08:48<14:58:59,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 11999/42000 [10:30<22:31, 22.20it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:98000\n",
      "Train Loss:0.31736063957214355\n",
      "Validation Loss:0.387339323759079\n",
      "Test Error:0.14110004901885986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 12001/42000 [10:31<12:28:40,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 13999/42000 [12:00<20:47, 22.45it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:100000\n",
      "Train Loss:0.3604574501514435\n",
      "Validation Loss:0.424084335565567\n",
      "Test Error:0.14840000867843628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 14002/42000 [12:13<10:27:30,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 16000/42000 [13:43<19:27, 22.26it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:102000\n",
      "Train Loss:0.3361474871635437\n",
      "Validation Loss:0.3772505223751068\n",
      "Test Error:0.1420000195503235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 16003/42000 [13:56<9:41:45,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 17998/42000 [15:37<17:48, 22.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:104000\n",
      "Train Loss:0.28682345151901245\n",
      "Validation Loss:0.35478153824806213\n",
      "Test Error:0.12639999389648438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 18001/42000 [15:38<8:57:06,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19999/42000 [17:20<16:23, 22.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:106000\n",
      "Train Loss:0.27693769335746765\n",
      "Validation Loss:0.3707357943058014\n",
      "Test Error:0.13090002536773682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 20001/42000 [17:21<9:05:53,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 21999/42000 [18:52<15:06, 22.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:108000\n",
      "Train Loss:0.30927860736846924\n",
      "Validation Loss:0.35372957587242126\n",
      "Test Error:0.13700002431869507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 22002/42000 [19:05<7:30:15,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 24000/42000 [20:47<13:19, 22.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:110000\n",
      "Train Loss:0.2713042199611664\n",
      "Validation Loss:0.34289753437042236\n",
      "Test Error:0.12220001220703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 24001/42000 [20:48<8:18:47,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 25999/42000 [22:30<11:51, 22.50it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:112000\n",
      "Train Loss:0.3468833565711975\n",
      "Validation Loss:0.4306904971599579\n",
      "Test Error:0.14329999685287476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 26001/42000 [22:31<6:38:23,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 27999/42000 [24:00<10:49, 21.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:114000\n",
      "Train Loss:0.34838271141052246\n",
      "Validation Loss:0.39993754029273987\n",
      "Test Error:0.14219999313354492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 28002/42000 [24:14<5:14:33,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 30000/42000 [25:43<09:00, 22.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:116000\n",
      "Train Loss:0.265550822019577\n",
      "Validation Loss:0.35589101910591125\n",
      "Test Error:0.12639999389648438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 30003/42000 [25:57<4:29:36,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 31998/42000 [27:37<07:41, 21.69it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:118000\n",
      "Train Loss:0.34313708543777466\n",
      "Validation Loss:0.4439244270324707\n",
      "Test Error:0.15540003776550293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 32001/42000 [27:40<3:45:14,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 33999/42000 [29:10<06:03, 22.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:120000\n",
      "Train Loss:0.3338101804256439\n",
      "Validation Loss:0.3894059956073761\n",
      "Test Error:0.14079999923706055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 34002/42000 [29:23<3:00:18,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 36000/42000 [30:53<04:32, 22.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:122000\n",
      "Train Loss:0.2929958403110504\n",
      "Validation Loss:0.37388598918914795\n",
      "Test Error:0.13530004024505615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 36003/42000 [31:07<2:15:04,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 37998/42000 [32:47<02:59, 22.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:124000\n",
      "Train Loss:0.26342615485191345\n",
      "Validation Loss:0.3551349937915802\n",
      "Test Error:0.12130004167556763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 38001/42000 [32:49<1:29:13,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 39999/42000 [34:30<01:29, 22.38it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:126000\n",
      "Train Loss:0.3198850452899933\n",
      "Validation Loss:0.40604719519615173\n",
      "Test Error:0.13600003719329834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 40001/42000 [34:32<49:51,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to out/resnet/resnet_ckpt_cifar.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42000/42000 [36:01<00:00, 19.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from train import Trainer\n",
    "trainer = Trainer(train_set, val_set, test_set,train_config, model_config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/projects/experiments-with-gpt2/vision_models/eval.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(self.eval_config.checkpoint_path,map_location=self.eval_config.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of parameters in the model: 272464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]/home/varun/projects/experiments-with-gpt2/vision_models/eval.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(batch[\"label\"]).to(self.eval_config.device)\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8639999628067017\n",
      "Error: 0.13600003719329834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from eval import Eval\n",
    "from cifar10 import cifar10\n",
    "from resnet_config import ResNetTestConfig, ResNetConfig\n",
    "evaluator = Eval(test_set=cifar10(\"test\"),eval_config=ResNetTestConfig(),model_config=ResNetConfig)\n",
    "evaluator.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
